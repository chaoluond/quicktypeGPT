# Introduction
Popular large language models (LLMs) like ChatGPT 3.5/4, Claude 2, Google Gemini, and Meta Llama 70 are gigantic models which have tens or hunderends billions of parameters and require hundreds/thousands Gigbytes memory and server-grade GPUs to train, finetune and inference. This sets a high bar for individual developers to explore possibilities of LLMs and make applications on top of it. Inspired by @karpathy's [llama2.c](https://github.com/karpathy/llama2.c) project, I developed quicktypeGPT.   

